{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mod√®le lin√©aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#################COURS##################\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.google.com/document/d/1lZiLLt7zLAzyVnv6MvYyIP8WlA3wXH9gQ5pUJmPQepQ/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://docs.google.com/document/d/1lZiLLt7zLAzyVnv6MvYyIP8WlA3wXH9gQ5pUJmPQepQ/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consid√©rons la cas classique d'une fonction affine :\n",
    "$$y=ax+b$$\n",
    "\n",
    "Ici, $a$ et $b$ sont des r√©els. Ces deux nombres d√©finissent enti√®rement la courbe et permet donc d'obtenir une relation affine entre $x$ et $y$. En statistique, cette relation est √† la base des mod√®les dit lin√©aires, o√π une variable r√©ponse se d√©finit comme une somme de variables explicatives o√π chacune de ces derni√®res sont multipli√©s par un coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mod√®le lin√©aire simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le mod√®le lin√©aire simple (une seule variable explicative), on suppose que la variable r√©ponse suit le mod√®le suivant :\n",
    "$$y_i=\\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n",
    "\n",
    "On remarque la ressemblance avec la fonction affine pr√©sent√©e ci-dessus. La diff√©rence r√©side dans l'existence du terme al√©atoire (appel√© bruit) $\\varepsilon_i$. Afin de consid√©rer le mod√®le, il est n√©cessaire de se placer sous les hypoth√®ses suivantes\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix} \\mathbb{E}[\\varepsilon_i]=0\\\\ \\text{Cov}(\\varepsilon_i, \\varepsilon_j)=\\delta_{ij} \\sigma^2 \\end{matrix}\\right.$$\n",
    "\n",
    "Les diff√©rents √©l√©ments qui interviennent sont :\n",
    "\n",
    "    $\\beta_0$ : l'ordonn√©e √† l'origine (nomm√©e intercept)\n",
    "    $\\beta_1$ : le coefficient directeur\n",
    "    $x_i$ : l'observation $i$\n",
    "    $y_i$ : le $i$-√®me prix\n",
    "    $\\varepsilon_i$ : le bruit al√©atoire li√©e √† la $i$-√®me observation\n",
    "\n",
    "La solution peut se calculer facilement via les formules ferm√©es suivantes :\n",
    "$$\\hat{\\beta}_1=\\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\qquad \\hat{\\beta}_0 = \\hat{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mod√®le lin√©aire multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas multiple (pour $p$ variables explicatives), pour la $i$-√®me observation, le mod√®le s'√©crit :\n",
    "$$y_i= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} + \\varepsilon_i$$\n",
    "\n",
    "Ainsi, une observation $x_i$ n'est plus une valeur, mais un vecteur $(x_{i1}, \\dots, x_{ip})$. Il est plus commode de regrouper ces prix $y_i$ et ces vecteurs d'observations $x_i$ dans des matrices :\n",
    "$$Y=X \\beta + \\varepsilon$$\n",
    "\n",
    "Sous les hypoth√®ses √©quivalentes du mod√®le simple en plus grand dimension\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix} \\text{rank}(X)=p\\\\ \\mathbb{E}[\\varepsilon]=0 \\text{ et }\\text{Var}(\\varepsilon)=\\sigma^2 I_p \\end{matrix}\\right.$$\n",
    "\n",
    "Les diff√©rents √©l√©ments qui interviennent sont :\n",
    "\n",
    "    $\\beta$ : le vecteur directeur\n",
    "    $X$ : la matrice des observations\n",
    "    $Y$ : le vecteur de prix\n",
    "    $\\varepsilon$ : le vecteur de bruit\n",
    "\n",
    "Avec $X=( \\mathbf{1}, X_1, \\dots, X_n)$, $Y=(y_1, \\dots, y_n)^\\top$ et $\\varepsilon=(\\varepsilon_1, \\dots, \\varepsilon_n)^\\top$. La solution des MCO (Moindres Carr√©s Ordinaires) est alors :\n",
    "$$\\hat{\\beta}= (X^\\top X)^{-1} X^\\top Y$$\n",
    "\n",
    "Vous pouvez d'ailleurs faire la d√©monstration de votre cot√© ! Pour plus d'information math√©matiques, le portail de wikip√©dia qui est tr√®s bien fait : lien ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl√©menter une r√©gression lin√©aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U scikit-learn\n",
    "import sklearn \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charger les donn√©es \n",
    "#price_availability.csv\n",
    "#listings_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7: expected 1 fields, saw 2\\nSkipping line 31: expected 1 fields, saw 4\\nSkipping line 53: expected 1 fields, saw 2\\nSkipping line 54: expected 1 fields, saw 3\\nSkipping line 57: expected 1 fields, saw 3\\nSkipping line 65: expected 1 fields, saw 2\\nSkipping line 89: expected 1 fields, saw 2\\nSkipping line 100: expected 1 fields, saw 3\\nSkipping line 102: expected 1 fields, saw 3\\nSkipping line 110: expected 1 fields, saw 2\\nSkipping line 111: expected 1 fields, saw 3\\nSkipping line 113: expected 1 fields, saw 2\\nSkipping line 120: expected 1 fields, saw 2\\nSkipping line 133: expected 1 fields, saw 2\\nSkipping line 136: expected 1 fields, saw 3\\nSkipping line 141: expected 1 fields, saw 2\\nSkipping line 151: expected 1 fields, saw 2\\nSkipping line 153: expected 1 fields, saw 3\\nSkipping line 154: expected 1 fields, saw 2\\nSkipping line 168: expected 1 fields, saw 3\\nSkipping line 182: expected 1 fields, saw 2\\nSkipping line 187: expected 1 fields, saw 2\\nSkipping line 199: expected 1 fields, saw 2\\nSkipping line 208: expected 1 fields, saw 2\\nSkipping line 211: expected 1 fields, saw 2\\nSkipping line 230: expected 1 fields, saw 3\\nSkipping line 245: expected 1 fields, saw 2\\nSkipping line 257: expected 1 fields, saw 2\\nSkipping line 263: expected 1 fields, saw 2\\nSkipping line 275: expected 1 fields, saw 3\\nSkipping line 281: expected 1 fields, saw 2\\nSkipping line 308: expected 1 fields, saw 2\\nSkipping line 312: expected 1 fields, saw 2\\nSkipping line 315: expected 1 fields, saw 3\\nSkipping line 316: expected 1 fields, saw 2\\nSkipping line 330: expected 1 fields, saw 2\\nSkipping line 332: expected 1 fields, saw 3\\nSkipping line 335: expected 1 fields, saw 3\\nSkipping line 336: expected 1 fields, saw 3\\nSkipping line 343: expected 1 fields, saw 3\\nSkipping line 344: expected 1 fields, saw 2\\nSkipping line 349: expected 1 fields, saw 2\\nSkipping line 353: expected 1 fields, saw 2\\nSkipping line 364: expected 1 fields, saw 3\\nSkipping line 385: expected 1 fields, saw 2\\nSkipping line 394: expected 1 fields, saw 3\\nSkipping line 400: expected 1 fields, saw 3\\nSkipping line 404: expected 1 fields, saw 2\\nSkipping line 407: expected 1 fields, saw 3\\nSkipping line 409: expected 1 fields, saw 3\\nSkipping line 422: expected 1 fields, saw 3\\nSkipping line 426: expected 1 fields, saw 3\\nSkipping line 431: expected 1 fields, saw 2\\nSkipping line 435: expected 1 fields, saw 3\\nSkipping line 441: expected 1 fields, saw 3\\nSkipping line 451: expected 1 fields, saw 3\\nSkipping line 457: expected 1 fields, saw 2\\nSkipping line 459: expected 1 fields, saw 2\\nSkipping line 466: expected 1 fields, saw 2\\nSkipping line 468: expected 1 fields, saw 2\\nSkipping line 476: expected 1 fields, saw 2\\nSkipping line 482: expected 1 fields, saw 3\\nSkipping line 489: expected 1 fields, saw 2\\nSkipping line 498: expected 1 fields, saw 3\\nSkipping line 501: expected 1 fields, saw 3\\nSkipping line 506: expected 1 fields, saw 3\\nSkipping line 509: expected 1 fields, saw 2\\nSkipping line 519: expected 1 fields, saw 4\\nSkipping line 528: expected 1 fields, saw 3\\nSkipping line 534: expected 1 fields, saw 2\\nSkipping line 538: expected 1 fields, saw 3\\nSkipping line 544: expected 1 fields, saw 3\\nSkipping line 549: expected 1 fields, saw 2\\nSkipping line 559: expected 1 fields, saw 2\\nSkipping line 563: expected 1 fields, saw 6\\nSkipping line 578: expected 1 fields, saw 2\\nSkipping line 588: expected 1 fields, saw 2\\nSkipping line 591: expected 1 fields, saw 2\\nSkipping line 599: expected 1 fields, saw 2\\nSkipping line 609: expected 1 fields, saw 2\\nSkipping line 622: expected 1 fields, saw 2\\nSkipping line 624: expected 1 fields, saw 3\\nSkipping line 625: expected 1 fields, saw 2\\nSkipping line 628: expected 1 fields, saw 3\\nSkipping line 631: expected 1 fields, saw 3\\nSkipping line 636: expected 1 fields, saw 3\\nSkipping line 640: expected 1 fields, saw 3\\nSkipping line 642: expected 1 fields, saw 3\\nSkipping line 660: expected 1 fields, saw 4\\nSkipping line 662: expected 1 fields, saw 3\\nSkipping line 674: expected 1 fields, saw 2\\nSkipping line 678: expected 1 fields, saw 2\\nSkipping line 685: expected 1 fields, saw 2\\nSkipping line 690: expected 1 fields, saw 2\\nSkipping line 696: expected 1 fields, saw 2\\nSkipping line 716: expected 1 fields, saw 2\\nSkipping line 718: expected 1 fields, saw 2\\nSkipping line 721: expected 1 fields, saw 2\\nSkipping line 731: expected 1 fields, saw 2\\nSkipping line 733: expected 1 fields, saw 2\\nSkipping line 753: expected 1 fields, saw 2\\nSkipping line 767: expected 1 fields, saw 2\\nSkipping line 786: expected 1 fields, saw 3\\nSkipping line 789: expected 1 fields, saw 3\\nSkipping line 817: expected 1 fields, saw 2\\nSkipping line 820: expected 1 fields, saw 3\\nSkipping line 831: expected 1 fields, saw 3\\nSkipping line 845: expected 1 fields, saw 2\\nSkipping line 848: expected 1 fields, saw 2\\nSkipping line 875: expected 1 fields, saw 2\\nSkipping line 887: expected 1 fields, saw 2\\nSkipping line 896: expected 1 fields, saw 2\\nSkipping line 909: expected 1 fields, saw 2\\nSkipping line 952: expected 1 fields, saw 2\\nSkipping line 953: expected 1 fields, saw 2\\nSkipping line 960: expected 1 fields, saw 2\\nSkipping line 994: expected 1 fields, saw 2\\n'\n"
     ]
    }
   ],
   "source": [
    "listing_df = pd.read_csv(\"listings_final.csv\", error_bad_lines=False)\n",
    "# problem solved on https://stackoverflow.com/questions/18039057/python-pandas-error-tokenizing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.read_csv(\"price_availability.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donn√©es d'entr√©e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif ici est de charger les donn√©es pour cr√©er les matrices $X$ et $Y$ du mod√®le lin√©aire. Attention, il n'est pas n√©cessaire de rajouter le vecteur colonne $\\mathbf{1}$ en premi√®re colonne, car scikit-learn le fait automatiquement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#############dtypes et head()############\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id;day;created;available;local_currency;local_price;min_nights    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id;day;created;available;local_currency;local_price;min_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9810829;2018-12-08;2018-09-27 06:14:10.000+000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9810829;2018-12-08;2018-09-26 19:34:02.000+000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20897010;2018-12-09;2018-09-27 10:38:57.000+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20897010;2018-12-09;2018-09-27 06:10:27.000+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20897010;2018-12-09;2018-09-26 19:30:25.000+00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id;day;created;available;local_currency;local_price;min_nights\n",
       "0  9810829;2018-12-08;2018-09-27 06:14:10.000+000...                    \n",
       "1  9810829;2018-12-08;2018-09-26 19:34:02.000+000...                    \n",
       "2  20897010;2018-12-09;2018-09-27 10:38:57.000+00...                    \n",
       "3  20897010;2018-12-09;2018-09-27 06:10:27.000+00...                    \n",
       "4  20897010;2018-12-09;2018-09-26 19:30:25.000+00...                    "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ";listing_id;name;type;city;neighborhood;latitude;longitude;person_capacity;beds;bedrooms;bathrooms;is_rebookable;is_new_listing;is_fully_refundable;is_host_highly_rated;is_business_travel_ready;pricing_weekly_factor;pricing_monthly_factor    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>;listing_id;name;type;city;neighborhood;latitude;longitude;person_capacity;beds;bedrooms;bathrooms;is_rebookable;is_new_listing;is_fully_refundable;is_host_highly_rated;is_business_travel_ready;pricing_weekly_factor;pricing_monthly_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0;28581061;La maison Clery;private_room;Paris;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1;661961;studio PARIS PLACE EDITH PIAF 75020;e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2;1261705;chambre priv√©e √† louer @ paris oberk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3;1318834;Appartement au coeur du Marais;entir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4;1677091;Lovely &amp; Quiet flat;entire_home;Pari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ;listing_id;name;type;city;neighborhood;latitude;longitude;person_capacity;beds;bedrooms;bathrooms;is_rebookable;is_new_listing;is_fully_refundable;is_host_highly_rated;is_business_travel_ready;pricing_weekly_factor;pricing_monthly_factor\n",
       "0  0;28581061;La maison Clery;private_room;Paris;...                                                                                                                                                                                            \n",
       "1  1;661961;studio PARIS PLACE EDITH PIAF 75020;e...                                                                                                                                                                                            \n",
       "2  2;1261705;chambre priv√©e √† louer @ paris oberk...                                                                                                                                                                                            \n",
       "3  3;1318834;Appartement au coeur du Marais;entir...                                                                                                                                                                                            \n",
       "4  4;1677091;Lovely & Quiet flat;entire_home;Pari...                                                                                                                                                                                            "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d√©finir 2 variables de travail\n",
    "#X := les features √† utiliser \n",
    "#Y := la target (prix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construire l'ensemble de donn√©e prix \n",
    "#\n",
    "#    INDICE \n",
    "# \n",
    "# r√©cup√©rer les prix des ID dans le dataset de prix \n",
    "# üöß il y a plusieurs prix dans le dataset üöß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En Machine Learning, on a l'habitude de couper l'ensemble de donn√©es en deux sous-ensembles :\n",
    "\n",
    "    Un ensemble d'entra√Ænement (train set), sur lequel le mod√®le va √™tre calibr√©.\n",
    "    Un ensemble de test (test set), qui ne sera pas utilis√© pendant le calibrage mais permettra de v√©rifier l'aptitude du mod√®le √† g√©n√©raliser sur de nouvelles observations inconnues.\n",
    "\n",
    "En g√©n√©ral, on d√©coupe l'ensemble de donn√©es (split) en prenant $\\alpha \\%$ de l'ensemble pour entra√Ænement et $1-\\alpha \\%$ comme test. Dans la plus part des cas, on consid√®re que $\\alpha=10,20 ou 30\\%$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utiliser la m√©thode split de sklearn en splitant avec un alpha=30 et un random state=42 \n",
    "#zafficher la shape de vos donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entra√Ænement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour information, scikit-learn utilise le solveur OLS (Ordinary Least Squares) de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr√©er l'objet de r√©gression et entrainer le sur notre ensemble d'entra√Ænement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche le vecteur des coefficients pour interpr√©ter rapidement le mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher les coefficients\n",
    "#que remarquez vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le coefficient de d√©termination $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite, nous ferons l'hypoth√®se de gaussianit√© sur les bruits. Dans l'id√©e, nous aimerions obtenir une valeur num√©rique qui nous indique √† quel point la r√©gression lin√©aire a un sens sur nos donn√©es. Pour cela, introduisons les notations suivantes :\n",
    "\n",
    "    $SCT=\\|Y-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carr√©s totaux\n",
    "    $SCE=\\|\\hat{Y}-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carr√©s expliqu√©s\n",
    "    $SCR=\\|\\hat{\\varepsilon}\\|^2$ est la somme des carr√©s r√©siduels\n",
    "\n",
    "L'id√©e est de d√©composer la somme des carr√©s totaux comme la somme des carr√©s que le mod√®le explique, en plus de la somme des carr√©s qui sont li√©s aux r√©sidus (et donc que le mod√®le ne peut pas expliquer). On voit donc ici l'int√©r√™t de calculer un coefficient √† partir du $SCE$. Puisque l'on a la relation suivante :\n",
    "$$SCT=SCE+SCR \\text{ alors } 1=\\frac{SCE}{SCT}+\\frac{SCR}{SCT}$$\n",
    "\n",
    "Plus les r√©sidus sont petits (et donc la r√©gression est \"bonne\"), plus $SCR$ devient petit et donc $SCE$ devient grand. Le sch√©ma inverse s'op√®re de la m√™me fa√ßon. Dans le meilleur des cas, on obtient $SCR=0$ et donc $SCE=SCT$ d'o√π le premier membre vaut $1$. Dans le cas contraite, $SCE=0$ et automatiquement, le premier membre est nul. C'est ainsi que l'on d√©finit le coefficient de d√©termination $R^2$ comme $$R^2=\\frac{SCE}{SCT}=1-\\frac{SCR}{SCT}$$ Ainsi, $R^2 \\in [0,1]$. Plus $R^2$ est proche de $1$, plus la r√©gression lin√©aire a du sens. Au contraire, si $R^2$ est proche de $0$, le mod√®le lin√©aire poss√®de un faible pouvoir explicatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faire une prediction sur X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher l'erreur des moindres carr√©es sur l'ensemble d'entrainement ainsi que le R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : Analyse de l'homosc√©dasticit√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de l'homosc√©dasticit√© est primordiale : c'est en particulier elle qui nous permet de v√©rifier, √† partir des r√©sidus, si les bruits v√©rifient bien l'hypoth√®se $(\\mathcal{H})$. On calcule donc les r√©sidus studentis√©s.\n",
    "$$t_i^*=\\frac{\\hat{\\varepsilon}_i}{\\hat{\\sigma}_{(i)} \\sqrt{1-h_{ii}}}$$\n",
    "\n",
    "Avec $h_{ii}=\\{X(X^\\top X)^{-1} X^\\top\\}_{ii}=H_{ii}$ la matrice de projection sur l'hyperplan des variables. Plus pr√©cis√©ment, $H$ est la matrice qui projette $Y$ sur l'espace engendr√© par les variables, soit $\\hat{Y}=HY$. De m√™me, on consid√®re $\\hat{\\sigma}_{(i)}$ l'estimateur de la variance du bruit en supprimant l'observation $i$ (par une m√©thode de validation crois√©e Leave-One-Out que nous ne d√©taillerons pas ici).\n",
    "\n",
    "Dans ce cas, on peut montrer que les r√©sidus studentis√©s suivent une loi de Student √† $n-p-1$ degr√©s de libert√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#analyser le code ci-dessous \\nimport scipy\\nY_pred = regr.predict(X_train)\\nn = X_train.shape[0]\\np = 4\\nresiduals = np.abs(y_train - Y_pred)\\nH = np.matmul(X_train, np.linalg.solve(np.dot(X_train.T, X_train), X_train.T))\\nstd_hat = np.dot(residuals, residuals) / (n - p)\\nstandart_residuals = np.asarray([residuals[i] / np.sqrt(std_hat * (1 - H[i, i])) for i in range(len(residuals))])\\nstudent_residuals = np.asarray([ standart_residuals[i] * np.sqrt((n - p - 1) / (n - p - standart_residuals[i]**2)) for i in range(n) ])\\ncook = np.asarray([ H[i, i] * student_residuals[i] / (X_train.shape[1] * (1 - H[i, i])) for i in range(n) ])\\n\\nplt.figure(figsize=(20, 12))\\nplt.subplot(221)\\nplt.scatter(Y_pred, student_residuals, s=12, c=\"white\", edgecolors=\"blue\")\\nplt.plot([min(Y_pred), max(Y_pred)], [ scipy.stats.t.ppf(q=0.975, df=n-p-1), scipy.stats.t.ppf(q=0.975, df=n-p-1)], color=\"green\", alpha=0.6, label=\"Quantile de Student\")\\nplt.title(\"Analyse de l‚Äôhomosc√©dasticit√©\")\\nplt.xlabel(\"Pr√©dictions $\\\\hat{y}_i$\")\\nplt.ylabel(\"R√©sidus studentis√©s $|t_i^*|$\")\\nplt.legend()\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#analyser le code ci-dessous \n",
    "import scipy\n",
    "Y_pred = regr.predict(X_train)\n",
    "n = X_train.shape[0]\n",
    "p = 4\n",
    "residuals = np.abs(y_train - Y_pred)\n",
    "H = np.matmul(X_train, np.linalg.solve(np.dot(X_train.T, X_train), X_train.T))\n",
    "std_hat = np.dot(residuals, residuals) / (n - p)\n",
    "standart_residuals = np.asarray([residuals[i] / np.sqrt(std_hat * (1 - H[i, i])) for i in range(len(residuals))])\n",
    "student_residuals = np.asarray([ standart_residuals[i] * np.sqrt((n - p - 1) / (n - p - standart_residuals[i]**2)) for i in range(n) ])\n",
    "cook = np.asarray([ H[i, i] * student_residuals[i] / (X_train.shape[1] * (1 - H[i, i])) for i in range(n) ])\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(221)\n",
    "plt.scatter(Y_pred, student_residuals, s=12, c=\"white\", edgecolors=\"blue\")\n",
    "plt.plot([min(Y_pred), max(Y_pred)], [ scipy.stats.t.ppf(q=0.975, df=n-p-1), scipy.stats.t.ppf(q=0.975, df=n-p-1)], color=\"green\", alpha=0.6, label=\"Quantile de Student\")\n",
    "plt.title(\"Analyse de l‚Äôhomosc√©dasticit√©\")\n",
    "plt.xlabel(\"Pr√©dictions $\\hat{y}_i$\")\n",
    "plt.ylabel(\"R√©sidus studentis√©s $|t_i^*|$\")\n",
    "plt.legend()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
