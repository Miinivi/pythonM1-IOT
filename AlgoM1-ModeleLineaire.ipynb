{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#################COURS##################\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.google.com/document/d/1lZiLLt7zLAzyVnv6MvYyIP8WlA3wXH9gQ5pUJmPQepQ/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://docs.google.com/document/d/1lZiLLt7zLAzyVnv6MvYyIP8WlA3wXH9gQ5pUJmPQepQ/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons la cas classique d'une fonction affine :\n",
    "$$y=ax+b$$\n",
    "\n",
    "Ici, $a$ et $b$ sont des réels. Ces deux nombres définissent entièrement la courbe et permet donc d'obtenir une relation affine entre $x$ et $y$. En statistique, cette relation est à la base des modèles dit linéaires, où une variable réponse se définit comme une somme de variables explicatives où chacune de ces dernières sont multipliés par un coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle linéaire simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le modèle linéaire simple (une seule variable explicative), on suppose que la variable réponse suit le modèle suivant :\n",
    "$$y_i=\\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n",
    "\n",
    "On remarque la ressemblance avec la fonction affine présentée ci-dessus. La différence réside dans l'existence du terme aléatoire (appelé bruit) $\\varepsilon_i$. Afin de considérer le modèle, il est nécessaire de se placer sous les hypothèses suivantes\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix} \\mathbb{E}[\\varepsilon_i]=0\\\\ \\text{Cov}(\\varepsilon_i, \\varepsilon_j)=\\delta_{ij} \\sigma^2 \\end{matrix}\\right.$$\n",
    "\n",
    "Les différents éléments qui interviennent sont :\n",
    "\n",
    "    $\\beta_0$ : l'ordonnée à l'origine (nommée intercept)\n",
    "    $\\beta_1$ : le coefficient directeur\n",
    "    $x_i$ : l'observation $i$\n",
    "    $y_i$ : le $i$-ème prix\n",
    "    $\\varepsilon_i$ : le bruit aléatoire liée à la $i$-ème observation\n",
    "\n",
    "La solution peut se calculer facilement via les formules fermées suivantes :\n",
    "$$\\hat{\\beta}_1=\\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\qquad \\hat{\\beta}_0 = \\hat{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle linéaire multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas multiple (pour $p$ variables explicatives), pour la $i$-ème observation, le modèle s'écrit :\n",
    "$$y_i= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} + \\varepsilon_i$$\n",
    "\n",
    "Ainsi, une observation $x_i$ n'est plus une valeur, mais un vecteur $(x_{i1}, \\dots, x_{ip})$. Il est plus commode de regrouper ces prix $y_i$ et ces vecteurs d'observations $x_i$ dans des matrices :\n",
    "$$Y=X \\beta + \\varepsilon$$\n",
    "\n",
    "Sous les hypothèses équivalentes du modèle simple en plus grand dimension\n",
    "$$(\\mathcal{H}) : \\left\\{\\begin{matrix} \\text{rank}(X)=p\\\\ \\mathbb{E}[\\varepsilon]=0 \\text{ et }\\text{Var}(\\varepsilon)=\\sigma^2 I_p \\end{matrix}\\right.$$\n",
    "\n",
    "Les différents éléments qui interviennent sont :\n",
    "\n",
    "    $\\beta$ : le vecteur directeur\n",
    "    $X$ : la matrice des observations\n",
    "    $Y$ : le vecteur de prix\n",
    "    $\\varepsilon$ : le vecteur de bruit\n",
    "\n",
    "Avec $X=( \\mathbf{1}, X_1, \\dots, X_n)$, $Y=(y_1, \\dots, y_n)^\\top$ et $\\varepsilon=(\\varepsilon_1, \\dots, \\varepsilon_n)^\\top$. La solution des MCO (Moindres Carrés Ordinaires) est alors :\n",
    "$$\\hat{\\beta}= (X^\\top X)^{-1} X^\\top Y$$\n",
    "\n",
    "Vous pouvez d'ailleurs faire la démonstration de votre coté ! Pour plus d'information mathématiques, le portail de wikipédia qui est très bien fait : lien ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémenter une régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U scikit-learn\n",
    "import sklearn \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charger les données \n",
    "#price_availability.csv\n",
    "#listings_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7: expected 1 fields, saw 2\\nSkipping line 31: expected 1 fields, saw 4\\nSkipping line 53: expected 1 fields, saw 2\\nSkipping line 54: expected 1 fields, saw 3\\nSkipping line 57: expected 1 fields, saw 3\\nSkipping line 65: expected 1 fields, saw 2\\nSkipping line 89: expected 1 fields, saw 2\\nSkipping line 100: expected 1 fields, saw 3\\nSkipping line 102: expected 1 fields, saw 3\\nSkipping line 110: expected 1 fields, saw 2\\nSkipping line 111: expected 1 fields, saw 3\\nSkipping line 113: expected 1 fields, saw 2\\nSkipping line 120: expected 1 fields, saw 2\\nSkipping line 133: expected 1 fields, saw 2\\nSkipping line 136: expected 1 fields, saw 3\\nSkipping line 141: expected 1 fields, saw 2\\nSkipping line 151: expected 1 fields, saw 2\\nSkipping line 153: expected 1 fields, saw 3\\nSkipping line 154: expected 1 fields, saw 2\\nSkipping line 168: expected 1 fields, saw 3\\nSkipping line 182: expected 1 fields, saw 2\\nSkipping line 187: expected 1 fields, saw 2\\nSkipping line 199: expected 1 fields, saw 2\\nSkipping line 208: expected 1 fields, saw 2\\nSkipping line 211: expected 1 fields, saw 2\\nSkipping line 230: expected 1 fields, saw 3\\nSkipping line 245: expected 1 fields, saw 2\\nSkipping line 257: expected 1 fields, saw 2\\nSkipping line 263: expected 1 fields, saw 2\\nSkipping line 275: expected 1 fields, saw 3\\nSkipping line 281: expected 1 fields, saw 2\\nSkipping line 308: expected 1 fields, saw 2\\nSkipping line 312: expected 1 fields, saw 2\\nSkipping line 315: expected 1 fields, saw 3\\nSkipping line 316: expected 1 fields, saw 2\\nSkipping line 330: expected 1 fields, saw 2\\nSkipping line 332: expected 1 fields, saw 3\\nSkipping line 335: expected 1 fields, saw 3\\nSkipping line 336: expected 1 fields, saw 3\\nSkipping line 343: expected 1 fields, saw 3\\nSkipping line 344: expected 1 fields, saw 2\\nSkipping line 349: expected 1 fields, saw 2\\nSkipping line 353: expected 1 fields, saw 2\\nSkipping line 364: expected 1 fields, saw 3\\nSkipping line 385: expected 1 fields, saw 2\\nSkipping line 394: expected 1 fields, saw 3\\nSkipping line 400: expected 1 fields, saw 3\\nSkipping line 404: expected 1 fields, saw 2\\nSkipping line 407: expected 1 fields, saw 3\\nSkipping line 409: expected 1 fields, saw 3\\nSkipping line 422: expected 1 fields, saw 3\\nSkipping line 426: expected 1 fields, saw 3\\nSkipping line 431: expected 1 fields, saw 2\\nSkipping line 435: expected 1 fields, saw 3\\nSkipping line 441: expected 1 fields, saw 3\\nSkipping line 451: expected 1 fields, saw 3\\nSkipping line 457: expected 1 fields, saw 2\\nSkipping line 459: expected 1 fields, saw 2\\nSkipping line 466: expected 1 fields, saw 2\\nSkipping line 468: expected 1 fields, saw 2\\nSkipping line 476: expected 1 fields, saw 2\\nSkipping line 482: expected 1 fields, saw 3\\nSkipping line 489: expected 1 fields, saw 2\\nSkipping line 498: expected 1 fields, saw 3\\nSkipping line 501: expected 1 fields, saw 3\\nSkipping line 506: expected 1 fields, saw 3\\nSkipping line 509: expected 1 fields, saw 2\\nSkipping line 519: expected 1 fields, saw 4\\nSkipping line 528: expected 1 fields, saw 3\\nSkipping line 534: expected 1 fields, saw 2\\nSkipping line 538: expected 1 fields, saw 3\\nSkipping line 544: expected 1 fields, saw 3\\nSkipping line 549: expected 1 fields, saw 2\\nSkipping line 559: expected 1 fields, saw 2\\nSkipping line 563: expected 1 fields, saw 6\\nSkipping line 578: expected 1 fields, saw 2\\nSkipping line 588: expected 1 fields, saw 2\\nSkipping line 591: expected 1 fields, saw 2\\nSkipping line 599: expected 1 fields, saw 2\\nSkipping line 609: expected 1 fields, saw 2\\nSkipping line 622: expected 1 fields, saw 2\\nSkipping line 624: expected 1 fields, saw 3\\nSkipping line 625: expected 1 fields, saw 2\\nSkipping line 628: expected 1 fields, saw 3\\nSkipping line 631: expected 1 fields, saw 3\\nSkipping line 636: expected 1 fields, saw 3\\nSkipping line 640: expected 1 fields, saw 3\\nSkipping line 642: expected 1 fields, saw 3\\nSkipping line 660: expected 1 fields, saw 4\\nSkipping line 662: expected 1 fields, saw 3\\nSkipping line 674: expected 1 fields, saw 2\\nSkipping line 678: expected 1 fields, saw 2\\nSkipping line 685: expected 1 fields, saw 2\\nSkipping line 690: expected 1 fields, saw 2\\nSkipping line 696: expected 1 fields, saw 2\\nSkipping line 716: expected 1 fields, saw 2\\nSkipping line 718: expected 1 fields, saw 2\\nSkipping line 721: expected 1 fields, saw 2\\nSkipping line 731: expected 1 fields, saw 2\\nSkipping line 733: expected 1 fields, saw 2\\nSkipping line 753: expected 1 fields, saw 2\\nSkipping line 767: expected 1 fields, saw 2\\nSkipping line 786: expected 1 fields, saw 3\\nSkipping line 789: expected 1 fields, saw 3\\nSkipping line 817: expected 1 fields, saw 2\\nSkipping line 820: expected 1 fields, saw 3\\nSkipping line 831: expected 1 fields, saw 3\\nSkipping line 845: expected 1 fields, saw 2\\nSkipping line 848: expected 1 fields, saw 2\\nSkipping line 875: expected 1 fields, saw 2\\nSkipping line 887: expected 1 fields, saw 2\\nSkipping line 896: expected 1 fields, saw 2\\nSkipping line 909: expected 1 fields, saw 2\\nSkipping line 952: expected 1 fields, saw 2\\nSkipping line 953: expected 1 fields, saw 2\\nSkipping line 960: expected 1 fields, saw 2\\nSkipping line 994: expected 1 fields, saw 2\\n'\n"
     ]
    }
   ],
   "source": [
    "listing_df = pd.read_csv(\"listings_final.csv\", error_bad_lines=False)\n",
    "# problem solved on https://stackoverflow.com/questions/18039057/python-pandas-error-tokenizing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.read_csv(\"price_availability.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif ici est de charger les données pour créer les matrices $X$ et $Y$ du modèle linéaire. Attention, il n'est pas nécessaire de rajouter le vecteur colonne $\\mathbf{1}$ en première colonne, car scikit-learn le fait automatiquement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#############dtypes et head()############\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id;day;created;available;local_currency;local_price;min_nights    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id;day;created;available;local_currency;local_price;min_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9810829;2018-12-08;2018-09-27 06:14:10.000+000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9810829;2018-12-08;2018-09-26 19:34:02.000+000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20897010;2018-12-09;2018-09-27 10:38:57.000+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20897010;2018-12-09;2018-09-27 06:10:27.000+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20897010;2018-12-09;2018-09-26 19:30:25.000+00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id;day;created;available;local_currency;local_price;min_nights\n",
       "0  9810829;2018-12-08;2018-09-27 06:14:10.000+000...                    \n",
       "1  9810829;2018-12-08;2018-09-26 19:34:02.000+000...                    \n",
       "2  20897010;2018-12-09;2018-09-27 10:38:57.000+00...                    \n",
       "3  20897010;2018-12-09;2018-09-27 06:10:27.000+00...                    \n",
       "4  20897010;2018-12-09;2018-09-26 19:30:25.000+00...                    "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ";listing_id;name;type;city;neighborhood;latitude;longitude;person_capacity;beds;bedrooms;bathrooms;is_rebookable;is_new_listing;is_fully_refundable;is_host_highly_rated;is_business_travel_ready;pricing_weekly_factor;pricing_monthly_factor    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>;listing_id;name;type;city;neighborhood;latitude;longitude;person_capacity;beds;bedrooms;bathrooms;is_rebookable;is_new_listing;is_fully_refundable;is_host_highly_rated;is_business_travel_ready;pricing_weekly_factor;pricing_monthly_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0;28581061;La maison Clery;private_room;Paris;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1;661961;studio PARIS PLACE EDITH PIAF 75020;e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2;1261705;chambre privée à louer @ paris oberk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3;1318834;Appartement au coeur du Marais;entir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4;1677091;Lovely &amp; Quiet flat;entire_home;Pari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ;listing_id;name;type;city;neighborhood;latitude;longitude;person_capacity;beds;bedrooms;bathrooms;is_rebookable;is_new_listing;is_fully_refundable;is_host_highly_rated;is_business_travel_ready;pricing_weekly_factor;pricing_monthly_factor\n",
       "0  0;28581061;La maison Clery;private_room;Paris;...                                                                                                                                                                                            \n",
       "1  1;661961;studio PARIS PLACE EDITH PIAF 75020;e...                                                                                                                                                                                            \n",
       "2  2;1261705;chambre privée à louer @ paris oberk...                                                                                                                                                                                            \n",
       "3  3;1318834;Appartement au coeur du Marais;entir...                                                                                                                                                                                            \n",
       "4  4;1677091;Lovely & Quiet flat;entire_home;Pari...                                                                                                                                                                                            "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#définir 2 variables de travail\n",
    "#X := les features à utiliser \n",
    "#Y := la target (prix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construire l'ensemble de donnée prix \n",
    "#\n",
    "#    INDICE \n",
    "# \n",
    "# récupérer les prix des ID dans le dataset de prix \n",
    "# 🚧 il y a plusieurs prix dans le dataset 🚧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En Machine Learning, on a l'habitude de couper l'ensemble de données en deux sous-ensembles :\n",
    "\n",
    "    Un ensemble d'entraînement (train set), sur lequel le modèle va être calibré.\n",
    "    Un ensemble de test (test set), qui ne sera pas utilisé pendant le calibrage mais permettra de vérifier l'aptitude du modèle à généraliser sur de nouvelles observations inconnues.\n",
    "\n",
    "En général, on découpe l'ensemble de données (split) en prenant $\\alpha \\%$ de l'ensemble pour entraînement et $1-\\alpha \\%$ comme test. Dans la plus part des cas, on considère que $\\alpha=10,20 ou 30\\%$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utiliser la méthode split de sklearn en splitant avec un alpha=30 et un random state=42 \n",
    "#zafficher la shape de vos données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour information, scikit-learn utilise le solveur OLS (Ordinary Least Squares) de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#créer l'objet de régression et entrainer le sur notre ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche le vecteur des coefficients pour interpréter rapidement le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher les coefficients\n",
    "#que remarquez vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le coefficient de détermination $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite, nous ferons l'hypothèse de gaussianité sur les bruits. Dans l'idée, nous aimerions obtenir une valeur numérique qui nous indique à quel point la régression linéaire a un sens sur nos données. Pour cela, introduisons les notations suivantes :\n",
    "\n",
    "    $SCT=\\|Y-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carrés totaux\n",
    "    $SCE=\\|\\hat{Y}-\\hat{y} \\mathbf{1}\\|^2$ est la somme des carrés expliqués\n",
    "    $SCR=\\|\\hat{\\varepsilon}\\|^2$ est la somme des carrés résiduels\n",
    "\n",
    "L'idée est de décomposer la somme des carrés totaux comme la somme des carrés que le modèle explique, en plus de la somme des carrés qui sont liés aux résidus (et donc que le modèle ne peut pas expliquer). On voit donc ici l'intérêt de calculer un coefficient à partir du $SCE$. Puisque l'on a la relation suivante :\n",
    "$$SCT=SCE+SCR \\text{ alors } 1=\\frac{SCE}{SCT}+\\frac{SCR}{SCT}$$\n",
    "\n",
    "Plus les résidus sont petits (et donc la régression est \"bonne\"), plus $SCR$ devient petit et donc $SCE$ devient grand. Le schéma inverse s'opère de la même façon. Dans le meilleur des cas, on obtient $SCR=0$ et donc $SCE=SCT$ d'où le premier membre vaut $1$. Dans le cas contraite, $SCE=0$ et automatiquement, le premier membre est nul. C'est ainsi que l'on définit le coefficient de détermination $R^2$ comme $$R^2=\\frac{SCE}{SCT}=1-\\frac{SCR}{SCT}$$ Ainsi, $R^2 \\in [0,1]$. Plus $R^2$ est proche de $1$, plus la régression linéaire a du sens. Au contraire, si $R^2$ est proche de $0$, le modèle linéaire possède un faible pouvoir explicatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faire une prediction sur X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher l'erreur des moindres carrées sur l'ensemble d'entrainement ainsi que le R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : Analyse de l'homoscédasticité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de l'homoscédasticité est primordiale : c'est en particulier elle qui nous permet de vérifier, à partir des résidus, si les bruits vérifient bien l'hypothèse $(\\mathcal{H})$. On calcule donc les résidus studentisés.\n",
    "$$t_i^*=\\frac{\\hat{\\varepsilon}_i}{\\hat{\\sigma}_{(i)} \\sqrt{1-h_{ii}}}$$\n",
    "\n",
    "Avec $h_{ii}=\\{X(X^\\top X)^{-1} X^\\top\\}_{ii}=H_{ii}$ la matrice de projection sur l'hyperplan des variables. Plus précisément, $H$ est la matrice qui projette $Y$ sur l'espace engendré par les variables, soit $\\hat{Y}=HY$. De même, on considère $\\hat{\\sigma}_{(i)}$ l'estimateur de la variance du bruit en supprimant l'observation $i$ (par une méthode de validation croisée Leave-One-Out que nous ne détaillerons pas ici).\n",
    "\n",
    "Dans ce cas, on peut montrer que les résidus studentisés suivent une loi de Student à $n-p-1$ degrés de liberté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#analyser le code ci-dessous \\nimport scipy\\nY_pred = regr.predict(X_train)\\nn = X_train.shape[0]\\np = 4\\nresiduals = np.abs(y_train - Y_pred)\\nH = np.matmul(X_train, np.linalg.solve(np.dot(X_train.T, X_train), X_train.T))\\nstd_hat = np.dot(residuals, residuals) / (n - p)\\nstandart_residuals = np.asarray([residuals[i] / np.sqrt(std_hat * (1 - H[i, i])) for i in range(len(residuals))])\\nstudent_residuals = np.asarray([ standart_residuals[i] * np.sqrt((n - p - 1) / (n - p - standart_residuals[i]**2)) for i in range(n) ])\\ncook = np.asarray([ H[i, i] * student_residuals[i] / (X_train.shape[1] * (1 - H[i, i])) for i in range(n) ])\\n\\nplt.figure(figsize=(20, 12))\\nplt.subplot(221)\\nplt.scatter(Y_pred, student_residuals, s=12, c=\"white\", edgecolors=\"blue\")\\nplt.plot([min(Y_pred), max(Y_pred)], [ scipy.stats.t.ppf(q=0.975, df=n-p-1), scipy.stats.t.ppf(q=0.975, df=n-p-1)], color=\"green\", alpha=0.6, label=\"Quantile de Student\")\\nplt.title(\"Analyse de l’homoscédasticité\")\\nplt.xlabel(\"Prédictions $\\\\hat{y}_i$\")\\nplt.ylabel(\"Résidus studentisés $|t_i^*|$\")\\nplt.legend()\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#analyser le code ci-dessous \n",
    "import scipy\n",
    "Y_pred = regr.predict(X_train)\n",
    "n = X_train.shape[0]\n",
    "p = 4\n",
    "residuals = np.abs(y_train - Y_pred)\n",
    "H = np.matmul(X_train, np.linalg.solve(np.dot(X_train.T, X_train), X_train.T))\n",
    "std_hat = np.dot(residuals, residuals) / (n - p)\n",
    "standart_residuals = np.asarray([residuals[i] / np.sqrt(std_hat * (1 - H[i, i])) for i in range(len(residuals))])\n",
    "student_residuals = np.asarray([ standart_residuals[i] * np.sqrt((n - p - 1) / (n - p - standart_residuals[i]**2)) for i in range(n) ])\n",
    "cook = np.asarray([ H[i, i] * student_residuals[i] / (X_train.shape[1] * (1 - H[i, i])) for i in range(n) ])\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(221)\n",
    "plt.scatter(Y_pred, student_residuals, s=12, c=\"white\", edgecolors=\"blue\")\n",
    "plt.plot([min(Y_pred), max(Y_pred)], [ scipy.stats.t.ppf(q=0.975, df=n-p-1), scipy.stats.t.ppf(q=0.975, df=n-p-1)], color=\"green\", alpha=0.6, label=\"Quantile de Student\")\n",
    "plt.title(\"Analyse de l’homoscédasticité\")\n",
    "plt.xlabel(\"Prédictions $\\hat{y}_i$\")\n",
    "plt.ylabel(\"Résidus studentisés $|t_i^*|$\")\n",
    "plt.legend()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
